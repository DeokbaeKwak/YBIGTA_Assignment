{"cells":[{"cell_type":"markdown","metadata":{"id":"LYL2un0Ov-lr"},"source":["# **Recurrent Neural Networks - 필수 과제**\n","\n","**LSTM**을 구현해봅시다!\n","<br><br><br>\n","**필요 사전 지식**:\n","\n","- <u>PyTorch</u> (선택 과제 1)\n","\n","<br>\n","\n","**추가 사전 지식**: (알면 좋으나 몰라도 괜찮음)\n","\n","- <u>Tokenization</u>, <u>Word Embedding</u> (선택 과제 2)\n","\n","<br><br><br><br><br>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5-dfwtQv-lu","executionInfo":{"status":"ok","timestamp":1690167215105,"user_tz":-540,"elapsed":18581,"user":{"displayName":"곽민규","userId":"02203885658643663319"}},"outputId":"499d0bdd-165b-4ab4-f300-10b2aeaf66f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"]}],"source":["!pip install transformers\n","!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01BiODPJv-lv"},"outputs":[],"source":["import torch\n","from torch import nn, optim\n","from torch.utils.data import DataLoader\n","\n","from transformers import AutoModel, AutoTokenizer\n","from datasets import load_dataset\n","\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"iC-bWNBOv-lv"},"source":["<br><br>\n","\n","[Hugging Face](https://huggingface.co)에서 [Rotten Tomatoes dataset](https://huggingface.co/datasets/rotten_tomatoes)과 [pretrained BERT](https://huggingface.co/bert-base-uncased)의 tokenizer를 가져오겠습니다.\n","\n","또 학습 부담을 줄이기 위해 pretrained BERT에 내장된 word embedding layer의 weight도 가져옵시다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["4a33d94161d24eb2acbab39eabda0a00","f52da3b8f78d4c2380710b674df52652","ab746996c27a478b8256442b63bf5227","7ca43c703f294347b468dad7cfee97f0","9cedf699cb244c1580241e083018f149","d6f85a39e9c84d6e84f18b9e3cce8571","e78ac8154fea4a11a542009ebed32e27","885a5df0410e43c98f53f02394221ece","2b114c393384493995be1c4e6adb4008","c9da36e2fd6a4caeb14a4395932c709a","6356f1e9527d47dca9970a7531216679"]},"id":"yhT7l-zhv-lw","executionInfo":{"status":"ok","timestamp":1690167230548,"user_tz":-540,"elapsed":6820,"user":{"displayName":"곽민규","userId":"02203885658643663319"}},"outputId":"c6bddab6-44f9-4ff5-f089-4815d54ef06e"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a33d94161d24eb2acbab39eabda0a00"}},"metadata":{}}],"source":["# https://huggingface.co/datasets/rotten_tomatoes\n","dataset = load_dataset(\"rotten_tomatoes\")\n","\n","# https://huggingface.co/bert-base-uncased\n","pretrained_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","pretrained_embeddings = AutoModel.from_pretrained(\"bert-base-uncased\").embeddings.word_embeddings"]},{"cell_type":"markdown","metadata":{"id":"scikBur4v-lw"},"source":["<br><br>\n","\n","기본 BERT는 token을 768차원 벡터로 embedding합니다. 우리의 작은 dataset과 작은 모델에게 768차원은 부담스러우니 PCA를 사용해 64차원으로 줄여줍시다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Id14RC89v-lw"},"outputs":[],"source":["nano_embed = torch.pca_lowrank(pretrained_embeddings.weight.detach(), q=64)[0]"]},{"cell_type":"markdown","metadata":{"id":"QgQU7_4av-lw"},"source":["<br><br>\n","\n","그런데 무작정 64차원으로 줄여도 되는 걸까요? BERT의 d_model이 괜히 768도 아닐 테고, 정보의 손실이 아주 클 것 같은데 말입니다.\n","\n","궁금하니 코사인 유사도로 축소된 embedding layer에 token들의 정보가 그럭저럭 잘 남아있는지 확인해봅시다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBYsUdGyv-lx","executionInfo":{"status":"ok","timestamp":1690167248844,"user_tz":-540,"elapsed":17601,"user":{"displayName":"곽민규","userId":"02203885658643663319"}},"outputId":"f6247ad7-e5f7-489a-e1c8-3c8caa2be7fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.0000,  0.9961,  0.9972,  ...,  0.8675,  0.7559,  0.1519],\n","        [ 0.9961,  1.0000,  0.9958,  ...,  0.8505,  0.7011,  0.1302],\n","        [ 0.9972,  0.9958,  1.0000,  ...,  0.8903,  0.7543,  0.1311],\n","        ...,\n","        [ 0.8675,  0.8505,  0.8903,  ...,  1.0000,  0.9303,  0.1996],\n","        [ 0.7559,  0.7011,  0.7543,  ...,  0.9303,  1.0000, -0.0930],\n","        [ 0.1519,  0.1302,  0.1311,  ...,  0.1996, -0.0930,  1.0000]])"]},"metadata":{},"execution_count":5}],"source":["cos = (nano_embed @ nano_embed.T) / (nano_embed.abs() @ nano_embed.abs().T)\n","cos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Im2vf0N1v-lx","executionInfo":{"status":"ok","timestamp":1690167255249,"user_tz":-540,"elapsed":6416,"user":{"displayName":"곽민규","userId":"02203885658643663319"}},"outputId":"f4790531-e547-4821-c8b9-7be38c5ba78a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ceo',\n"," 'crash',\n"," 'ski',\n"," 'planner',\n"," 'lava',\n"," '##berto',\n"," 'crashed',\n"," 'serie',\n"," 'francisco',\n"," 'gaga',\n"," 'crashing',\n"," 'luigi',\n"," 'eco',\n"," 'survivor',\n"," '##iro',\n"," 'quake',\n"," 'crashes',\n"," '##ggio',\n"," 'campeonato',\n"," 'cancel']"]},"metadata":{},"execution_count":6}],"source":["# word에 다양한 값을 넣어보세요! tokenizer의 vocab에 없는 token에 대해서는 빈 list가 뜹니다.\n","word = \"mario\"\n","\n","([*map(pretrained_tokenizer.decode, cos[pretrained_tokenizer.vocab[word]].argsort(descending=True)[1:21])] if word in pretrained_tokenizer.vocab else [])"]},{"cell_type":"markdown","metadata":{"id":"e4Z_Fsvbv-lx"},"source":["꽤 잘 남아있는 것 같습니다.\n","\n","(TMI: 조금 더 욕심을 부려 한번 32차원으로 줄여보면 무시하기 어려운 정보의 손실을 체감할 수 있습니다.)\n","\n","<br><br>"]},{"cell_type":"markdown","metadata":{"id":"sRkrRx1mv-lx"},"source":["이제 LSTM을 구현합시다! 사실 원래 BiLSTM으로 하려고 했는데 underfitting이 심해서 그냥 plain LSTM으로 준비했습니다."]},{"cell_type":"markdown","metadata":{"id":"56iZkBf1v-lx"},"source":["<br><br><br><br>\n","#### <span style=\"color:red\">**<u>Q1.</u>**</span>\n","\n","`class LSTMCell`의 빈칸을 채우세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aq_gJJKmv-lx"},"outputs":[],"source":["class LSTMCell(nn.Module):\n","    def __init__(self, d_x, d_h): # d_x: x의 차원수 (scalar int)\n","                                  # d_h: h의 차원수 (scalar int)\n","        super().__init__()\n","        d_stack = d_x + d_h\n","        ######################### START OF YOUR CODE #########################\n","\n","        dim1 = d_stack\n","        dim2 = d_h\n","        dim3 = d_stack\n","        dim4 = d_h\n","        dim5 = d_stack\n","        dim6 = d_h\n","\n","        ########################## END OF YOUR CODE ##########################\n","        self.W_f = nn.Linear(d_stack, d_h)\n","        self.W_i = nn.Linear(dim1, dim2)\n","        self.W_C = nn.Linear(dim3, dim4)\n","        self.W_o = nn.Linear(dim5, dim6)\n","\n","\n","    # forward는 t-1의 h_{t-1}, C_{t-1}과 t의 x_t를 입력으로 받아 계산합니다.\n","\n","    def forward(self, x, h, C): # x: x_t\n","                                # h: h_{h-1}\n","                                # C: C_{t-1}\n","        stack = torch.cat([x, h])\n","        ######################### START OF YOUR CODE #########################\n","\n","        f =   self.W_f(stack).sigmoid()\n","        i =   self.W_i(stack).sigmoid()\n","        C_ =  self.W_C(stack).tanh()\n","\n","        C_t = f * C + i * C_\n","\n","        o =   self.W_o(stack).sigmoid()\n","        h_t = o * C_t.tanh()\n","\n","        ########################## END OF YOUR CODE ##########################\n","        return h_t, C_t"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"023tCt1rv-lx"},"outputs":[],"source":["class LSTM(nn.Module):\n","    def __init__(self, vocab_size, d_out, pretrained_embeddings):\n","        super().__init__()\n","        vocab_size = pretrained_embeddings.shape[0]\n","        d_h = d_model = pretrained_embeddings.shape[1]\n","\n","        self.embed = nn.Embedding(vocab_size, d_model, _weight=pretrained_embeddings.clone()) # word embedding layer\n","        self.cell = LSTMCell(d_x=d_model, d_h=d_h) # LSTM cell\n","        self.out = nn.Linear(d_h, d_out, bias=True) # output layer\n","\n","        self.h_init = nn.Parameter(torch.zeros(d_h), requires_grad=False) # initial h\n","        self.C_init = nn.Parameter(torch.zeros(d_h), requires_grad=False) # initial C\n","\n","    def forward(self, input_ids):\n","        embedded = self.embed(input_ids).squeeze()\n","\n","        h = self.h_init.clone() # h 초기화\n","        C = self.C_init.clone() # C 초기화\n","        for x in embedded:\n","            h, C = self.cell(x, h, C) # iterate over embedded sequence\n","\n","        return self.out(h).squeeze() # last hidden state를 output layer에 통과시킨 값을 반환"]},{"cell_type":"markdown","metadata":{"id":"bFIRQ5ZGv-ly"},"source":["<br><br><br><br>\n","#### <span style=\"color:red\">**<u>Q2.</u>**</span>\n","\n","Test accuracy가 0.7 이상이 되도록 모델을 훈련시키세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBIuRywWv-ly"},"outputs":[],"source":["######################### START OF YOUR CODE #########################\n","\n","# 필요에 따라 바꿔도 됩니다.\n","device = \"cuda\"\n","\n","########################## END OF YOUR CODE ##########################\n","\n","model = LSTM(vocab_size=pretrained_tokenizer.vocab_size, d_out=1, pretrained_embeddings=nano_embed).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8l-o9VGEv-ly"},"outputs":[],"source":["######################### START OF YOUR CODE #########################\n","\n","# learning rate을 적절히 수정해보세요.\n","lr = 0.005\n","\n","########################## END OF YOUR CODE ##########################\n","\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5X7w-jIv-lz"},"outputs":[],"source":["train_loader = DataLoader(dataset[\"train\"], shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmruF_Wjv-lz","executionInfo":{"status":"ok","timestamp":1690167506570,"user_tz":-540,"elapsed":250787,"user":{"displayName":"곽민규","userId":"02203885658643663319"}},"outputId":"0f7d2fa6-aa0e-45c0-ce5a-f1ab6b0b7188"},"outputs":[{"output_type":"stream","name":"stderr","text":["  6%|▌         | 506/8530 [00:14<03:49, 35.02it/s]"]},{"output_type":"stream","name":"stdout","text":["  500 iter: 0.6948505345582962\n"]},{"output_type":"stream","name":"stderr","text":[" 12%|█▏        | 1005/8530 [00:29<03:11, 39.38it/s]"]},{"output_type":"stream","name":"stdout","text":[" 1000 iter: 0.692382710814476\n"]},{"output_type":"stream","name":"stderr","text":[" 18%|█▊        | 1504/8530 [00:43<02:59, 39.22it/s]"]},{"output_type":"stream","name":"stdout","text":[" 1500 iter: 0.6941971641182899\n"]},{"output_type":"stream","name":"stderr","text":[" 24%|██▎       | 2005/8530 [00:58<02:39, 40.87it/s]"]},{"output_type":"stream","name":"stdout","text":[" 2000 iter: 0.6947045715749264\n"]},{"output_type":"stream","name":"stderr","text":[" 29%|██▉       | 2507/8530 [01:13<02:40, 37.60it/s]"]},{"output_type":"stream","name":"stdout","text":[" 2500 iter: 0.6946657166481018\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 3004/8530 [01:28<02:12, 41.86it/s]"]},{"output_type":"stream","name":"stdout","text":[" 3000 iter: 0.6909168909192085\n"]},{"output_type":"stream","name":"stderr","text":[" 41%|████      | 3505/8530 [01:42<02:20, 35.77it/s]"]},{"output_type":"stream","name":"stdout","text":[" 3500 iter: 0.6873792499303818\n"]},{"output_type":"stream","name":"stderr","text":[" 47%|████▋     | 4007/8530 [01:56<01:51, 40.39it/s]"]},{"output_type":"stream","name":"stdout","text":[" 4000 iter: 0.7060075025558472\n"]},{"output_type":"stream","name":"stderr","text":[" 53%|█████▎    | 4505/8530 [02:10<01:40, 40.05it/s]"]},{"output_type":"stream","name":"stdout","text":[" 4500 iter: 0.6205998992323876\n"]},{"output_type":"stream","name":"stderr","text":[" 59%|█████▊    | 5005/8530 [02:23<01:27, 40.41it/s]"]},{"output_type":"stream","name":"stdout","text":[" 5000 iter: 0.6370258466601372\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▍   | 5508/8530 [02:37<01:15, 39.96it/s]"]},{"output_type":"stream","name":"stdout","text":[" 5500 iter: 0.6536585940420627\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 6007/8530 [02:51<00:55, 45.39it/s]"]},{"output_type":"stream","name":"stdout","text":[" 6000 iter: 0.5947886527776718\n"]},{"output_type":"stream","name":"stderr","text":[" 76%|███████▋  | 6507/8530 [03:04<00:47, 42.54it/s]"]},{"output_type":"stream","name":"stdout","text":[" 6500 iter: 0.6058451569080353\n"]},{"output_type":"stream","name":"stderr","text":[" 82%|████████▏ | 7004/8530 [03:17<00:39, 38.50it/s]"]},{"output_type":"stream","name":"stdout","text":[" 7000 iter: 0.5708084152638913\n"]},{"output_type":"stream","name":"stderr","text":[" 88%|████████▊ | 7501/8530 [03:38<01:21, 12.62it/s]"]},{"output_type":"stream","name":"stdout","text":[" 7500 iter: 0.5665357069969177\n"]},{"output_type":"stream","name":"stderr","text":[" 94%|█████████▍| 8004/8530 [03:56<00:21, 24.74it/s]"]},{"output_type":"stream","name":"stdout","text":[" 8000 iter: 0.5446539802104234\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 8501/8530 [04:10<00:01, 25.44it/s]"]},{"output_type":"stream","name":"stdout","text":[" 8500 iter: 0.5365125090926885\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8530/8530 [04:11<00:00, 33.96it/s]\n"]}],"source":["######################### START OF YOUR CODE #########################\n","\n","# 필요에 따라 바꿔도 됩니다.\n","num_print = 500\n","num_batch = 10\n","\n","########################## END OF YOUR CODE ##########################\n","\n","\n","# train\n","\n","save_l = 0\n","optimizer.zero_grad()\n","for i, data in enumerate(tqdm(train_loader)):\n","    text, label = data[\"text\"][0], data[\"label\"][0]\n","    input_ids = pretrained_tokenizer.encode(text, return_tensors=\"pt\").to(device)\n","    y_pred = model(input_ids)\n","\n","    label = label.to(device) * 1.\n","    loss = criterion(y_pred.sigmoid(), label)\n","    loss.backward()\n","\n","    if not (i+1)%num_batch:\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","    save_l += loss.item()\n","    if not (i+1)%num_print:\n","        print(f\"{i+1:>5} iter: {save_l/num_print}\")\n","        save_l = 0"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5pYrfwNjv-lz","outputId":"b8387b06-74d2-429c-d760-a9769c9cf099","executionInfo":{"status":"ok","timestamp":1690167576267,"user_tz":-540,"elapsed":11516,"user":{"displayName":"곽민규","userId":"02203885658643663319"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1066/1066 [00:11<00:00, 95.65it/s] "]},{"output_type":"stream","name":"stdout","text":["Test accuracy: 0.7270168855534709\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["test_loader = DataLoader(dataset[\"test\"], shuffle=True)\n","\n","\n","# test\n","\n","res = torch.tensor(0)\n","with torch.no_grad():\n","    for i, data in enumerate(tqdm(test_loader)):\n","        text, label = data[\"text\"][0], data[\"label\"][0]\n","        input_ids = pretrained_tokenizer.encode(text, return_tensors=\"pt\").to(device)\n","        y_pred = model(input_ids)\n","        res += ((1 if y_pred > 0 else 0) == label)\n","\n","print(\"Test accuracy:\", res.item() / dataset[\"test\"].num_rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0eSG5cUSv-lz"},"outputs":[],"source":["# 관찰용\n","# n 값을 바꿔가며 훈련시킨 모델의 예측값을 구경해보세요\n","n = 589\n","\n","print(dataset[\"test\"][n])\n","with torch.no_grad():\n","    print(model(pretrained_tokenizer.encode(dataset[\"test\"][n][\"text\"], return_tensors=\"pt\").to(device)).sigmoid().item())"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4a33d94161d24eb2acbab39eabda0a00":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f52da3b8f78d4c2380710b674df52652","IPY_MODEL_ab746996c27a478b8256442b63bf5227","IPY_MODEL_7ca43c703f294347b468dad7cfee97f0"],"layout":"IPY_MODEL_9cedf699cb244c1580241e083018f149"}},"f52da3b8f78d4c2380710b674df52652":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6f85a39e9c84d6e84f18b9e3cce8571","placeholder":"​","style":"IPY_MODEL_e78ac8154fea4a11a542009ebed32e27","value":"100%"}},"ab746996c27a478b8256442b63bf5227":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_885a5df0410e43c98f53f02394221ece","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b114c393384493995be1c4e6adb4008","value":3}},"7ca43c703f294347b468dad7cfee97f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9da36e2fd6a4caeb14a4395932c709a","placeholder":"​","style":"IPY_MODEL_6356f1e9527d47dca9970a7531216679","value":" 3/3 [00:00&lt;00:00, 61.68it/s]"}},"9cedf699cb244c1580241e083018f149":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6f85a39e9c84d6e84f18b9e3cce8571":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e78ac8154fea4a11a542009ebed32e27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"885a5df0410e43c98f53f02394221ece":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b114c393384493995be1c4e6adb4008":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9da36e2fd6a4caeb14a4395932c709a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6356f1e9527d47dca9970a7531216679":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
